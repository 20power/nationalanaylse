{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机种子，保证可复现\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 数据路径与目标列\n",
    "CSV_PATH = \"wave3ndata.csv\"     # <-- 改为你的CSV路径\n",
    "TARGET_COL = \"adlab_c\"\n",
    "\n",
    "# 特征筛选阈值（与前面方案一致）\n",
    "CORR_TH = 0.05        # 与目标的绝对相关下限\n",
    "REDUNDANCY_TH = 0.90  # 特征-特征冗余阈值\n",
    "TOP_N = 30            # Feature-Reduced 的 Top-N\n",
    "\n",
    "# 输出目录\n",
    "OUTDIR = \"models_exp_HGB\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#工具函数集\n",
    "def eval_report(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"统一评估：回归指标 + 业务友好指标\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    y_round = np.clip(np.rint(y_pred), 0, 6).astype(int)\n",
    "    acc = accuracy_score(y_true, y_round)\n",
    "    within1 = float(np.mean(np.abs(y_true - y_round) <= 1))\n",
    "    return dict(MAE=mae, RMSE=rmse, R2=r2, Acc_rounded=acc, Within1=within1)\n",
    "\n",
    "def split_numeric(df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "    \"\"\"仅保留数值特征列，剔除目标列\"\"\"\n",
    "    return df[[c for c in df.columns if c != target_col and pd.api.types.is_numeric_dtype(df[c])]].copy()\n",
    "\n",
    "def detect_bin_con_cols(X: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"粗分二值/连续列：唯一值是否子集于{0,1}\"\"\"\n",
    "    bin_cols, con_cols = [], []\n",
    "    for c in X.columns:\n",
    "        vals = pd.unique(X[c].dropna())\n",
    "        if len(vals) and set(np.unique(vals)).issubset({0,1}):\n",
    "            bin_cols.append(c)\n",
    "        else:\n",
    "            con_cols.append(c)\n",
    "    return bin_cols, con_cols\n",
    "\n",
    "def fit_impute_stats(X_train: pd.DataFrame, bin_cols: List[str], con_cols: List[str]) -> dict:\n",
    "    \"\"\"训练集上拟合缺失填充值：二值=众数；连续=中位数\"\"\"\n",
    "    stats = {\"binary_modes\": {}, \"continuous_medians\": {}}\n",
    "    for c in bin_cols:\n",
    "        s = X_train[c]\n",
    "        stats[\"binary_modes\"][c] = float(s.mode().iloc[0]) if not s.dropna().empty else 0.0\n",
    "    for c in con_cols:\n",
    "        s = X_train[c]\n",
    "        stats[\"continuous_medians\"][c] = float(s.median()) if not s.dropna().empty else 0.0\n",
    "    return stats\n",
    "\n",
    "def apply_impute_inplace(X: pd.DataFrame, stats: dict) -> None:\n",
    "    \"\"\"按训练统计值原地填充缺失\"\"\"\n",
    "    for c, v in stats[\"binary_modes\"].items():\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].fillna(v)\n",
    "    for c, v in stats[\"continuous_medians\"].items():\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].fillna(v)\n",
    "\n",
    "def screen_features_on_train(\n",
    "    X_train: pd.DataFrame, y_train: np.ndarray,\n",
    "    corr_th: float, redundancy_th: float, top_n: int\n",
    ") -> List[str]:\n",
    "    \"\"\"三阶段筛选 + HGB 重要度选 Top-N（仅用训练集，以避免泄漏）\"\"\"\n",
    "    # 1) 低方差\n",
    "    vt = VarianceThreshold(0.0)\n",
    "    X1 = X_train.loc[:, vt.fit(X_train).get_support()]\n",
    "    # 2) 与目标相关\n",
    "    kept = []\n",
    "    for c in X1.columns:\n",
    "        try:\n",
    "            r = abs(pearsonr(X1[c], y_train)[0])\n",
    "        except Exception:\n",
    "            r = 0.0\n",
    "        if r > corr_th:\n",
    "            kept.append(c)\n",
    "    X2 = X1[kept] if kept else X1\n",
    "    # 3) 冗余\n",
    "    if X2.shape[1] > 1:\n",
    "        cm = X2.corr().abs()\n",
    "        upper = cm.where(np.triu(np.ones(cm.shape), k=1).astype(bool))\n",
    "        drop = [col for col in upper.columns if any(upper[col] > redundancy_th)]\n",
    "        X3 = X2.drop(columns=drop) if drop else X2\n",
    "    else:\n",
    "        X3 = X2\n",
    "    # 4) Top-N\n",
    "    if X3.shape[1] > 0:\n",
    "        hgb = HistGradientBoostingRegressor(\n",
    "            learning_rate=0.05, max_leaf_nodes=31, min_samples_leaf=20, random_state=RANDOM_STATE\n",
    "        )\n",
    "        hgb.fit(X3, y_train)\n",
    "        imps = pd.Series(hgb.feature_importances_, index=X3.columns).sort_values(ascending=False)\n",
    "        selected = imps.head(min(top_n, X3.shape[1])).index.tolist()\n",
    "    else:\n",
    "        selected = []\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5204, 63), (1302, 63), 47, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "assert TARGET_COL in df.columns, f\"CSV 中缺少目标列 {TARGET_COL}\"\n",
    "\n",
    "# 目标列裁剪到[0,6]并取整（避免脏标注；保证整数等级）\n",
    "df = df.dropna(subset=[TARGET_COL]).copy()\n",
    "df[TARGET_COL] = df[TARGET_COL].astype(float).round().clip(0,6).astype(int)\n",
    "\n",
    "# 数值特征与目标\n",
    "X_all = split_numeric(df, TARGET_COL)\n",
    "y_all = df[TARGET_COL].values\n",
    "\n",
    "# 分层切分（保持0~6各等级比例）\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=RANDOM_STATE, stratify=y_all\n",
    ")\n",
    "\n",
    "# 训练集上拟合缺失填充统计，并对Train/Test应用（防止信息泄漏）\n",
    "bin_cols, con_cols = detect_bin_con_cols(X_tr)\n",
    "impute_stats = fit_impute_stats(X_tr, bin_cols, con_cols)\n",
    "apply_impute_inplace(X_tr, impute_stats)\n",
    "apply_impute_inplace(X_te, impute_stats)\n",
    "\n",
    "X_tr.shape, X_te.shape, len(bin_cols), len(con_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11466\\Anaconda\\envs\\Yarn_prodiction\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.5755583554442748,\n",
       " 'RMSE': 0.9020973959150392,\n",
       " 'R2': 0.5691368284614929,\n",
       " 'Acc_rounded': 0.6382488479262672,\n",
       " 'Within1': 0.9001536098310292}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 纯HGB \n",
    "baseline_hgb = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.05, max_leaf_nodes=31, min_samples_leaf=20, random_state=RANDOM_STATE\n",
    ")\n",
    "baseline_hgb.fit(X_tr, y_tr)\n",
    "pred_base = baseline_hgb.predict(X_te)\n",
    "metrics_base = eval_report(y_te, pred_base)\n",
    "metrics_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.012512501432968153,\n",
       "  'max_leaf_nodes': 15,\n",
       "  'min_samples_leaf': 50,\n",
       "  'l2_regularization': 1.0,\n",
       "  'max_iter': 500},\n",
       " 0.5968994442463676)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#PSO+HGB\n",
    "# ----- PSO 配置（可调） -----\n",
    "SWARM_SIZE = 12        # 粒子数量（可增大提升稳定性）\n",
    "N_ITERS = 15           # 迭代轮数（可增大提升精度）\n",
    "W, C1, C2 = 0.6, 1.5, 1.5  # 惯性权重、个体/群体学习因子\n",
    "\n",
    "# 参数边界\n",
    "BOUNDS = {\n",
    "    \"learning_rate\": (0.01, 0.30),\n",
    "    \"max_leaf_nodes\": (15, 63),\n",
    "    \"min_samples_leaf\": (5, 50),\n",
    "    \"l2_regularization\": (0.0, 1.0),\n",
    "    \"max_iter\": (100, 500),\n",
    "}\n",
    "PARAM_KEYS = list(BOUNDS.keys())\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "def sample_position():\n",
    "    \"\"\"在边界内随机初始化一个粒子位置向量\"\"\"\n",
    "    pos = []\n",
    "    for k in PARAM_KEYS:\n",
    "        lo, hi = BOUNDS[k]\n",
    "        pos.append(rng.uniform(lo, hi))\n",
    "    return np.array(pos, dtype=float)\n",
    "\n",
    "def clip_position(pos):\n",
    "    \"\"\"将位置限制在边界内\"\"\"\n",
    "    clipped = pos.copy()\n",
    "    for i, k in enumerate(PARAM_KEYS):\n",
    "        lo, hi = BOUNDS[k]\n",
    "        clipped[i] = np.clip(clipped[i], lo, hi)\n",
    "    return clipped\n",
    "\n",
    "def position_to_params(pos):\n",
    "    \"\"\"将位置向量映射到HGB参数字典（需要取整的取整）\"\"\"\n",
    "    d = dict(zip(PARAM_KEYS, pos.tolist()))\n",
    "    d[\"max_leaf_nodes\"] = int(round(d[\"max_leaf_nodes\"]))\n",
    "    d[\"min_samples_leaf\"] = int(round(d[\"min_samples_leaf\"]))\n",
    "    d[\"max_iter\"] = int(round(d[\"max_iter\"]))\n",
    "    return d\n",
    "\n",
    "def cv_mae_for_params(params, X, y, n_splits=3):\n",
    "    \"\"\"给定参数在训练集上做K折分层CV，返回平均MAE（越小越好）\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    maes = []\n",
    "    for tr_idx, va_idx in skf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y[tr_idx], y[va_idx]\n",
    "        # 直接使用训练阶段的填充值与完整特征（不做特征筛选）以控制变量\n",
    "        model = HistGradientBoostingRegressor(\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            max_leaf_nodes=params[\"max_leaf_nodes\"],\n",
    "            min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "            l2_regularization=params[\"l2_regularization\"],\n",
    "            max_iter=params[\"max_iter\"],\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        model.fit(Xtr, ytr)\n",
    "        pred = model.predict(Xva)\n",
    "        maes.append(mean_absolute_error(yva, pred))\n",
    "    return float(np.mean(maes))\n",
    "\n",
    "# 初始化粒子群\n",
    "positions = np.stack([sample_position() for _ in range(SWARM_SIZE)], axis=0)\n",
    "velocities = rng.normal(loc=0.0, scale=0.1, size=positions.shape)\n",
    "\n",
    "# 个体/全局最优\n",
    "pbest_pos = positions.copy()\n",
    "pbest_val = np.array([\n",
    "    cv_mae_for_params(position_to_params(p), X_tr, y_tr) for p in positions\n",
    "], dtype=float)\n",
    "gbest_idx = int(np.argmin(pbest_val))\n",
    "gbest_pos = pbest_pos[gbest_idx].copy()\n",
    "gbest_val = pbest_val[gbest_idx].item()\n",
    "\n",
    "history = [gbest_val]\n",
    "\n",
    "# 迭代优化\n",
    "for it in range(N_ITERS):\n",
    "    for i in range(SWARM_SIZE):\n",
    "        r1, r2 = rng.random(len(PARAM_KEYS)), rng.random(len(PARAM_KEYS))\n",
    "        velocities[i] = (\n",
    "            W * velocities[i]\n",
    "            + C1 * r1 * (pbest_pos[i] - positions[i])\n",
    "            + C2 * r2 * (gbest_pos - positions[i])\n",
    "        )\n",
    "        positions[i] = clip_position(positions[i] + velocities[i])\n",
    "        # 评估\n",
    "        val = cv_mae_for_params(position_to_params(positions[i]), X_tr, y_tr)\n",
    "        if val < pbest_val[i]:\n",
    "            pbest_val[i] = val\n",
    "            pbest_pos[i] = positions[i].copy()\n",
    "            if val < gbest_val:\n",
    "                gbest_val = val\n",
    "                gbest_pos = positions[i].copy()\n",
    "    history.append(gbest_val)\n",
    "\n",
    "best_params_pso = position_to_params(gbest_pos)\n",
    "best_params_pso, history[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11466\\Anaconda\\envs\\Yarn_prodiction\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'MAE': 0.5665884240643839,\n",
       "  'RMSE': 0.8897181010294642,\n",
       "  'R2': 0.5808809817817147,\n",
       "  'Acc_rounded': 0.6397849462365591,\n",
       "  'Within1': 0.9024577572964669},\n",
       " {'learning_rate': 0.012512501432968153,\n",
       "  'max_leaf_nodes': 15,\n",
       "  'min_samples_leaf': 50,\n",
       "  'l2_regularization': 1.0,\n",
       "  'max_iter': 500})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb_pso = HistGradientBoostingRegressor(\n",
    "    **best_params_pso, random_state=RANDOM_STATE\n",
    ")\n",
    "hgb_pso.fit(X_tr, y_tr)\n",
    "pred_pso = hgb_pso.predict(X_te)\n",
    "metrics_pso = eval_report(y_te, pred_pso)\n",
    "metrics_pso, best_params_pso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11466\\Anaconda\\envs\\Yarn_prodiction\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.9139693804046484,\n",
       " 'RMSE': 1.1577039779696394,\n",
       " 'R2': 0.29037719028644315,\n",
       " 'Acc_rounded': 0.34715821812596004,\n",
       " 'Within1': 0.8233486943164362}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weight+HGB\n",
    "\n",
    "# 计算训练集各等级频率\n",
    "unique, counts = np.unique(y_tr, return_counts=True)\n",
    "freq = dict(zip(unique, counts))\n",
    "inv_freq = {k: 1.0 / v for k, v in freq.items()}\n",
    "\n",
    "# 将逆频率缩放到均值=1，避免权重过大影响收敛\n",
    "w = np.array([inv_freq[y] for y in y_tr], dtype=float)\n",
    "w = w * (len(w) / np.sum(w))  # scale so mean ~ 1\n",
    "\n",
    "# 使用与基线一致的模型结构，仅加入 sample_weight\n",
    "hgb_w = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.05, max_leaf_nodes=31, min_samples_leaf=20, random_state=RANDOM_STATE\n",
    ")\n",
    "hgb_w.fit(X_tr, y_tr, sample_weight=w)\n",
    "pred_w = hgb_w.predict(X_te)\n",
    "metrics_w = eval_report(y_te, pred_w)\n",
    "metrics_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Acc_rounded</th>\n",
       "      <th>Within1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline-HGB</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.9021</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>0.9002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSO-HGB</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>0.5809</td>\n",
       "      <td>0.6398</td>\n",
       "      <td>0.9025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weighted-HGB</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>1.1577</td>\n",
       "      <td>0.2904</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>0.8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Exp     MAE    RMSE      R2  Acc_rounded  Within1\n",
       "0  Baseline-HGB  0.5756  0.9021  0.5691       0.6382   0.9002\n",
       "1       PSO-HGB  0.5666  0.8897  0.5809       0.6398   0.9025\n",
       "2  Weighted-HGB  0.9140  1.1577  0.2904       0.3472   0.8233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame([\n",
    "    dict(Exp=\"Baseline-HGB\", **metrics_base),\n",
    "    dict(Exp=\"PSO-HGB\", **metrics_pso),\n",
    "    dict(Exp=\"Weighted-HGB\", **metrics_w),\n",
    "])\n",
    "\n",
    "# 四舍五入显示\n",
    "display(results.round(4))\n",
    "\n",
    "# 可选：保存结果\n",
    "results.to_csv(os.path.join(OUTDIR, \"exp_results_summary.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_to_plot = [\"MAE\",\"RMSE\",\"R2\",\"Acc_rounded\",\"Within1\"]\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "results_melt = results.melt(id_vars=\"Exp\", value_vars=metrics_to_plot, var_name=\"Metric\", value_name=\"Value\")\n",
    "for m in metrics_to_plot:\n",
    "    subset = results_melt[results_melt[\"Metric\"]==m]\n",
    "    ax.plot(subset[\"Exp\"], subset[\"Value\"], marker=\"o\", label=m)\n",
    "ax.set_title(\"Experiment Comparison (HGB Variants)\")\n",
    "ax.set_xticklabels(results[\"Exp\"], rotation=15)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yarn_prodiction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
